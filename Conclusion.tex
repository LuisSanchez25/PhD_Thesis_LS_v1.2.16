\section{Conclusion}

In this thesis my main focus was on using \glspl{som} for signal classification of dark matter \gls{tpc} experiments. We introduced dark matter and discussed candidates for this elusive form of matter. We focused on the promising \glspl{wimp} and discussed the \gls{tpc} technology used to try and detect these particles. We discussed two instances of this technology being used, XENONnT and XAMS and explained the data processing procedures. In both instances, we used CSOM to try and characterize and classify the waveforms produced by scintillation and ionization signals. We concluded this classification produced better results than the method that was implemented in the data processing pipelines. Additionally, we discussed some of my direct work in \gls{som} research and metadata management system in XENON.

In XENONnT, I improved the peaklet classification algorithm, implemented this new approach into our pipeline and developed the software necessary for others to reproduce my work. The \gls{som}-aided peaklet classification algorithm employed reduced the number of misclassified \gls{se} by half and misclassified S1s by roughly 30\%. Although the total percentage gain was small, this improvement had a significant impact in the reduction of our \gls{ac} background. The CSOM classification provided a finer-grained classification that can be used in future analysis for cuts and data selection. 

In XAMS I used \gls{som}-based clustering to identify the signals we observed. We provided a more fine-grained clustering aiding in signal characterization and identified a few clusters of interest that indicate unexpected feature of the \gls{pmt} used.

I also worked on improving the \gls{som} learning process by creating a stopping criterion based on signal migration between prototypes. This can be used as a proxy for a convergence metric indicating when we can stop training. This can both save computational resources and reduces the time analysts invest in the training process.

We also developed a metadata management system used in XENONnT, which is very flexible and general. It has rules that can be changed depending on the metadata management needs of different collaborations to ensure data integrity and it is easy to use. This has aided in ensuring our data is consistent and reliable and makes errors easy to fix by simply generating a new version of the metadata. (review this based on xedocs paper).

\subsection{Discussion}

The main obstacle for a wide range implementation of \gls{som}-based classification lies in the cluster identification. This requires some practice and experience from the user but tools such as the mU-matrix can greatly aid in the initial drawing of boundaries. The fine-tuning of these boundaries can be tedious as it requires extensive examination of each clusters and constant mapping between the \gls{som} grid space and physical parameters spaces the user can interpret. Ideally, a way of automating this cluster selection could greatly reduce the barrier to entry of this approach however these methods need to be further explored in the future.

Furthermore, I partially relied on the previous classification algorithm to first separate signals from noise or junk waveforms. In the future, it would be better if the \gls{som} classification can be applied to all the data as it could help us recover some signal efficiency for low energy interactions. This might require a selection of different parameters to generate the input vectors used for training.

If there is enough computational power, one might also consider having a voting system classification. Here tools like \glspl{svm}, Bayesian classifiers, supervised classification algorithms, amongst others could all be used to select  the signal type and they could vote on the classification of each signal. Different methods could provide different advantages and disadvantages, as such, this method could improve signal classification accuracy while also generating additional useful information such as the probabilities of each signal being an S1 or an S2.

Future experiments like XLZD can use this thesis as a general guide to train \gls{som} for future \gls{tpc} experiments. They can use \textsc{sciSOM} to generate weightcubes and generate clusters for classification. Furthermore, they can build and further develop the \gls{som} tools which helps the experiment have higher signal classification accuracy and develops the coding skills of the PhD students working in this project.
